<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>tests.test_backing_image API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>tests.test_backing_image</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import os
import subprocess

import pytest

from backupstore import set_random_backupstore, backupstore_cleanup  # NOQA
from common import client, random_labels, volume_name, core_api  # NOQA
from common import csi_pv, pvc, pod_make  # NOQA
from common import csi_pv_backingimage, pvc_backingimage  # NOQA
from common import disable_auto_salvage  # NOQA

from test_basic import volume_basic_test, volume_iscsi_basic_test, \
    snapshot_test, snapshot_prune_test, \
    snapshot_prune_and_coalesce_simultaneously, \
    backup_test, backup_labels_test
from test_engine_upgrade import engine_offline_upgrade_test, \
    engine_live_upgrade_test, engine_live_upgrade_rollback_test
from test_ha import ha_simple_recovery_test, ha_salvage_test, \
    ha_backup_deletion_recovery_test
from test_csi import csi_mount_test, csi_io_test, csi_backup_test
from test_recurring_job import recurring_job_labels_test

from common import get_self_host_id
from common import create_and_check_volume, wait_for_volume_healthy, \
    wait_for_volume_delete, cleanup_all_volumes
from common import create_backing_image_with_matching_url, \
    wait_for_backing_image_disk_cleanup, cleanup_all_backing_images
from common import get_volume_endpoint, mount_disk, cleanup_host_disk
from common import write_volume_random_data, check_volume_data
from common import cleanup_all_recurring_jobs

from common import BACKING_IMAGE_NAME, BACKING_IMAGE_QCOW2_URL, \
    BACKING_IMAGE_RAW_URL, BACKING_IMAGE_EXT4_SIZE, \
    DIRECTORY_PATH, BACKING_IMAGE_SOURCE_TYPE_DOWNLOAD, \
    BACKING_IMAGE_SOURCE_TYPE_FROM_VOLUME, Gi

from common import wait_for_volume_detached
from common import wait_for_backing_image_status
from common import wait_for_backing_image_in_disk_fail
from common import get_disk_uuid
from common import write_volume_dev_random_mb_data, get_device_checksum
from common import check_backing_image_disk_map_status
from common import LONGHORN_NAMESPACE, RETRY_EXEC_COUNTS, RETRY_INTERVAL
from common import BACKING_IMAGE_QCOW2_CHECKSUM
from common import BACKING_IMAGE_STATE_READY
from common import BACKING_IMAGE_STATE_FAILED_AND_CLEANUP
from common import BACKING_IMAGE_STATE_IN_PROGRESS
from common import RETRY_COUNTS_LONG
import time


@pytest.mark.coretest   # NOQA
@pytest.mark.backing_image  # NOQA
def test_backing_image_basic_operation(client, volume_name):  # NOQA
    for bi_url in (BACKING_IMAGE_QCOW2_URL, BACKING_IMAGE_RAW_URL):
        create_backing_image_with_matching_url(
            client, BACKING_IMAGE_NAME, bi_url)
        backing_image_basic_operation_test(
            client, volume_name, BACKING_IMAGE_NAME, bi_url)
        cleanup_all_volumes(client)
        cleanup_all_backing_images(client)


def backing_image_basic_operation_test(client, volume_name, bi_name, bi_url):  # NOQA
    &#34;&#34;&#34;
    Test Backing Image APIs.

    1. Create a backing image.
    2. Create and attach a Volume with the backing image set.
    3. Verify that the all disk states in the backing image are &#34;downloaded&#34;.
    4. Try to use the API to manually clean up one disk for the backing image
       but get failed.
    5. Try to use the API to directly delete the backing image
       but get failed.
    6. Delete the volume.
    7. Use the API to manually clean up one disk for the backing image
    8. Delete the backing image.
    &#34;&#34;&#34;

    volume = create_and_check_volume(
        client, volume_name, 3,
        str(BACKING_IMAGE_EXT4_SIZE), bi_name)
    lht_host_id = get_self_host_id()
    volume.attach(hostId=lht_host_id)
    volume = wait_for_volume_healthy(client, volume_name)
    assert volume.backingImage == bi_name
    assert volume.size == str(BACKING_IMAGE_EXT4_SIZE)

    random_disk_id = &#34;&#34;
    backing_image = client.by_id_backing_image(bi_name)
    assert backing_image.sourceType == BACKING_IMAGE_SOURCE_TYPE_DOWNLOAD
    assert backing_image.parameters[&#34;url&#34;] == bi_url
    assert backing_image.currentChecksum != &#34;&#34;
    assert not backing_image.deletionTimestamp
    assert len(backing_image.diskFileStatusMap) == 3
    for disk_id, status in iter(backing_image.diskFileStatusMap.items()):
        assert status.state == BACKING_IMAGE_STATE_READY
        random_disk_id = disk_id
    assert random_disk_id != &#39;&#39;

    with pytest.raises(Exception):
        backing_image.backingImageCleanup(disks=[random_disk_id])
    with pytest.raises(Exception):
        client.delete(backing_image)

    client.delete(volume)
    wait_for_volume_delete(client, volume_name)

    backing_image = client.by_id_backing_image(bi_name)
    backing_image.backingImageCleanup(disks=[random_disk_id])
    backing_image = wait_for_backing_image_disk_cleanup(
        client, bi_name, random_disk_id)
    client.delete(backing_image)


@pytest.mark.coretest   # NOQA
@pytest.mark.backing_image  # NOQA
def test_backing_image_content(client, volume_name):  # NOQA
    for bi_url in (BACKING_IMAGE_QCOW2_URL, BACKING_IMAGE_RAW_URL):
        create_backing_image_with_matching_url(
            client, BACKING_IMAGE_NAME, bi_url)
        backing_image_content_test(
            client, volume_name, BACKING_IMAGE_NAME, bi_url)
        cleanup_all_volumes(client)
        cleanup_all_backing_images(client)


def backing_image_content_test(client, volume_name_prefix, bi_name, bi_url):  # NOQA
    &#34;&#34;&#34;
    Verify the content of the Backing Image is accessible and read-only for
    all volumes.

    1. Create a backing image. (Done by the caller)
    2. Create a Volume with the backing image set then attach it to host node.
    3. Verify that the all disk states in the backing image are &#34;downloaded&#34;.
    4. Verify volume can be directly mounted and there is already data in the
       filesystem due to the backing image.
    5. Verify the volume r/w.
    6. Launch one more volume with the same backing image.
    7. Verify the data content of the new volume is the same as the data in
       step 4.
    5. Do cleanup. (Done by the caller)
    &#34;&#34;&#34;
    lht_host_id = get_self_host_id()

    volume_name1 = volume_name_prefix + &#34;-1&#34;
    volume1 = create_and_check_volume(
        client, volume_name1, 3,
        str(BACKING_IMAGE_EXT4_SIZE), bi_name)
    volume1.attach(hostId=lht_host_id)
    volume1 = wait_for_volume_healthy(client, volume_name1)
    assert volume1.backingImage == bi_name
    assert volume1.size == str(BACKING_IMAGE_EXT4_SIZE)

    backing_image = client.by_id_backing_image(bi_name)
    assert backing_image.sourceType == BACKING_IMAGE_SOURCE_TYPE_DOWNLOAD
    assert backing_image.parameters[&#34;url&#34;] == bi_url
    assert backing_image.currentChecksum != &#34;&#34;
    assert not backing_image.deletionTimestamp
    assert len(backing_image.diskFileStatusMap) == 3
    for disk_id, status in iter(backing_image.diskFileStatusMap.items()):
        assert status.state == BACKING_IMAGE_STATE_READY

    # Since there is already a filesystem with data in the backing image,
    # we can directly mount and access the volume without `mkfs`.
    dev1 = get_volume_endpoint(volume1)
    mount_path1 = os.path.join(DIRECTORY_PATH, volume_name1)
    mount_disk(dev1, mount_path1)
    output1 = subprocess.check_output([&#34;ls&#34;, mount_path1])
    # The following random write may crash the filesystem of volume1,
    # need to umount it here
    cleanup_host_disk(volume_name1)

    # Verify r/w for the volume with a backing image
    data = write_volume_random_data(volume1)
    check_volume_data(volume1, data)

    volume_name2 = volume_name_prefix + &#34;-2&#34;
    volume2 = create_and_check_volume(
        client, volume_name2, 3,
        str(BACKING_IMAGE_EXT4_SIZE), bi_name)
    volume2.attach(hostId=lht_host_id)
    volume2 = wait_for_volume_healthy(client, volume_name2)
    assert volume1.backingImage == bi_name
    assert volume1.size == str(BACKING_IMAGE_EXT4_SIZE)
    dev2 = get_volume_endpoint(volume2)
    mount_path2 = os.path.join(DIRECTORY_PATH, volume_name2)
    mount_disk(dev2, mount_path2)
    output2 = subprocess.check_output([&#34;ls&#34;, mount_path2])
    # The output is the content of the backing image, which should keep
    # unchanged
    assert output2 == output1

    cleanup_host_disk(volume_name2)


@pytest.mark.coretest   # NOQA
@pytest.mark.backing_image  # NOQA
def test_volume_basic_with_backing_image(client, volume_name):  # NOQA
    for bi_url in (BACKING_IMAGE_QCOW2_URL, BACKING_IMAGE_RAW_URL):
        create_backing_image_with_matching_url(
            client, BACKING_IMAGE_NAME, bi_url)
        volume_basic_test(client, volume_name, BACKING_IMAGE_NAME)
        cleanup_all_volumes(client)
        cleanup_all_backing_images(client)


@pytest.mark.coretest   # NOQA
@pytest.mark.backing_image  # NOQA
def test_volume_iscsi_basic_with_backing_image(client, volume_name):  # NOQA
    for bi_url in (BACKING_IMAGE_QCOW2_URL, BACKING_IMAGE_RAW_URL):
        create_backing_image_with_matching_url(
            client, BACKING_IMAGE_NAME, bi_url)
        volume_iscsi_basic_test(client, volume_name, BACKING_IMAGE_NAME)
        cleanup_all_volumes(client)
        cleanup_all_backing_images(client)


@pytest.mark.coretest   # NOQA
@pytest.mark.backing_image  # NOQA
def test_snapshot_with_backing_image(client, volume_name):  # NOQA
    for bi_url in (BACKING_IMAGE_QCOW2_URL, BACKING_IMAGE_RAW_URL):
        create_backing_image_with_matching_url(
            client, BACKING_IMAGE_NAME, bi_url)
        snapshot_test(client, volume_name, BACKING_IMAGE_NAME)
        cleanup_all_volumes(client)
        cleanup_all_backing_images(client)


@pytest.mark.coretest   # NOQA
@pytest.mark.backing_image  # NOQA
def test_snapshot_prune_with_backing_image(client, volume_name):  # NOQA
    for bi_url in (BACKING_IMAGE_QCOW2_URL, BACKING_IMAGE_RAW_URL):
        create_backing_image_with_matching_url(
            client, BACKING_IMAGE_NAME, bi_url)
        snapshot_prune_test(client, volume_name, BACKING_IMAGE_NAME)
        cleanup_all_volumes(client)
        cleanup_all_backing_images(client)


@pytest.mark.coretest   # NOQA
@pytest.mark.backing_image  # NOQA
def test_snapshot_prune_and_coalesce_simultaneously_with_backing_image(client, volume_name):  # NOQA
    for bi_url in (BACKING_IMAGE_QCOW2_URL, BACKING_IMAGE_RAW_URL):
        create_backing_image_with_matching_url(
            client, BACKING_IMAGE_NAME, bi_url)
        snapshot_prune_and_coalesce_simultaneously(
            client, volume_name, BACKING_IMAGE_NAME)
        cleanup_all_volumes(client)
        cleanup_all_backing_images(client)


@pytest.mark.coretest   # NOQA
@pytest.mark.backing_image  # NOQA
def test_backup_with_backing_image(set_random_backupstore, client, volume_name):  # NOQA
    for bi_url in (BACKING_IMAGE_QCOW2_URL, BACKING_IMAGE_RAW_URL):
        create_backing_image_with_matching_url(
            client, BACKING_IMAGE_NAME, bi_url)
        backup_test(client, volume_name, str(BACKING_IMAGE_EXT4_SIZE),
                    BACKING_IMAGE_NAME)
        cleanup_all_volumes(client)
        cleanup_all_backing_images(client)
        backupstore_cleanup(client)


@pytest.mark.coretest   # NOQA
@pytest.mark.backing_image  # NOQA
def test_backup_labels_with_backing_image(set_random_backupstore, client, random_labels, volume_name):  # NOQA
    for bi_url in (BACKING_IMAGE_QCOW2_URL, BACKING_IMAGE_RAW_URL):
        create_backing_image_with_matching_url(
            client, BACKING_IMAGE_NAME, bi_url)
        backup_labels_test(client, random_labels, volume_name,
                           str(BACKING_IMAGE_EXT4_SIZE), BACKING_IMAGE_NAME)
        cleanup_all_volumes(client)
        cleanup_all_backing_images(client)
        backupstore_cleanup(client)


@pytest.mark.coretest   # NOQA
@pytest.mark.backing_image  # NOQA
def test_ha_simple_recovery_with_backing_image(client, volume_name):  # NOQA
    for bi_url in (BACKING_IMAGE_QCOW2_URL, BACKING_IMAGE_RAW_URL):
        create_backing_image_with_matching_url(
            client, BACKING_IMAGE_NAME, bi_url)
        ha_simple_recovery_test(client, volume_name,
                                str(BACKING_IMAGE_EXT4_SIZE),
                                BACKING_IMAGE_NAME)
        cleanup_all_volumes(client)
        cleanup_all_backing_images(client)


@pytest.mark.backing_image  # NOQA
def test_ha_salvage_with_backing_image(client, core_api, disable_auto_salvage, volume_name):  # NOQA
    for bi_url in (BACKING_IMAGE_QCOW2_URL, BACKING_IMAGE_RAW_URL):
        create_backing_image_with_matching_url(
            client, BACKING_IMAGE_NAME, bi_url)
        ha_salvage_test(client, core_api, volume_name, BACKING_IMAGE_NAME)
        cleanup_all_volumes(client)
        cleanup_all_backing_images(client)


@pytest.mark.backing_image  # NOQA
def test_ha_backup_deletion_recovery(set_random_backupstore, client, volume_name):  # NOQA
    for bi_url in (BACKING_IMAGE_QCOW2_URL, BACKING_IMAGE_RAW_URL):
        create_backing_image_with_matching_url(
            client, BACKING_IMAGE_NAME, bi_url)
        ha_backup_deletion_recovery_test(client, volume_name,
                                         str(BACKING_IMAGE_EXT4_SIZE),
                                         BACKING_IMAGE_NAME)
        cleanup_all_volumes(client)
        cleanup_all_backing_images(client)
        backupstore_cleanup(client)


@pytest.mark.backing_image  # NOQA
def test_engine_offline_upgrade_with_backing_image(client, core_api, volume_name):  # NOQA
    for bi_url in (BACKING_IMAGE_QCOW2_URL, BACKING_IMAGE_RAW_URL):
        create_backing_image_with_matching_url(
            client, BACKING_IMAGE_NAME, bi_url)
        engine_offline_upgrade_test(client, core_api, volume_name,
                                    BACKING_IMAGE_NAME)
        cleanup_all_volumes(client)
        cleanup_all_backing_images(client)


@pytest.mark.coretest   # NOQA
@pytest.mark.backing_image  # NOQA
def test_engine_live_upgrade_with_backing_image(client, core_api, volume_name):  # NOQA
    for bi_url in (BACKING_IMAGE_QCOW2_URL, BACKING_IMAGE_RAW_URL):
        create_backing_image_with_matching_url(
            client, BACKING_IMAGE_NAME, bi_url)
        engine_live_upgrade_test(client, core_api, volume_name,
                                 BACKING_IMAGE_NAME)
        cleanup_all_volumes(client)
        cleanup_all_backing_images(client)


@pytest.mark.backing_image  # NOQA
def test_engine_live_upgrade_rollback_with_backing_image(client, core_api, volume_name):  # NOQA
    for bi_url in (BACKING_IMAGE_QCOW2_URL, BACKING_IMAGE_RAW_URL):
        create_backing_image_with_matching_url(
            client, BACKING_IMAGE_NAME, bi_url)
        engine_live_upgrade_rollback_test(client, core_api, volume_name,
                                          BACKING_IMAGE_NAME)
        cleanup_all_volumes(client)
        cleanup_all_backing_images(client)


@pytest.mark.backing_image  # NOQA
@pytest.mark.csi  # NOQA
def test_csi_mount_with_backing_image(client, core_api, csi_pv_backingimage, pvc_backingimage, pod_make):  # NOQA
    for bi_url in (BACKING_IMAGE_QCOW2_URL, BACKING_IMAGE_RAW_URL):
        create_backing_image_with_matching_url(
            client, BACKING_IMAGE_NAME, bi_url)
        csi_mount_test(client, core_api,
                       csi_pv_backingimage, pvc_backingimage, pod_make,
                       BACKING_IMAGE_EXT4_SIZE, BACKING_IMAGE_NAME)
        cleanup_all_volumes(client)
        cleanup_all_backing_images(client)


@pytest.mark.coretest   # NOQA
@pytest.mark.backing_image  # NOQA
@pytest.mark.csi  # NOQA
def test_csi_io_with_backing_image(client, core_api, csi_pv_backingimage, pvc_backingimage, pod_make):  # NOQA
    for bi_url in (BACKING_IMAGE_QCOW2_URL, BACKING_IMAGE_RAW_URL):
        create_backing_image_with_matching_url(
            client, BACKING_IMAGE_NAME, bi_url)
        csi_io_test(client, core_api,
                    csi_pv_backingimage, pvc_backingimage, pod_make)
        cleanup_all_volumes(client)
        cleanup_all_backing_images(client)


@pytest.mark.coretest  # NOQA
@pytest.mark.backing_image  # NOQA
@pytest.mark.csi  # NOQA
def test_csi_backup_with_backing_image(set_random_backupstore, client, core_api, csi_pv, pvc, pod_make):  # NOQA
    for bi_url in (BACKING_IMAGE_QCOW2_URL, BACKING_IMAGE_RAW_URL):
        create_backing_image_with_matching_url(
            client, BACKING_IMAGE_NAME, bi_url)
        csi_backup_test(client, core_api, csi_pv, pvc, pod_make,
                        BACKING_IMAGE_NAME)
        cleanup_all_volumes(client)
        cleanup_all_backing_images(client)
        backupstore_cleanup(client)


@pytest.mark.backing_image  # NOQA
@pytest.mark.recurring_job  # NOQA
def test_recurring_job_labels_with_backing_image(set_random_backupstore, client, random_labels, volume_name):  # NOQA
    for bi_url in (BACKING_IMAGE_QCOW2_URL, BACKING_IMAGE_RAW_URL):
        create_backing_image_with_matching_url(
            client, BACKING_IMAGE_NAME, bi_url)
        recurring_job_labels_test(client, random_labels, volume_name,
                                  str(BACKING_IMAGE_EXT4_SIZE),
                                  BACKING_IMAGE_NAME)
        cleanup_all_recurring_jobs(client)
        cleanup_all_volumes(client)
        cleanup_all_backing_images(client)
        backupstore_cleanup(client)


@pytest.mark.skip(reason=&#34;TODO&#34;) # NOQA
@pytest.mark.backing_image  # NOQA
def test_backing_image_with_disk_migration():  # NOQA
    &#34;&#34;&#34;
    1. Update settings:
       1. Disable Node Soft Anti-affinity.
       2. Set Replica Replenishment Wait Interval to a relatively long value.
    2. Create a new host disk.
    3. Disable the default disk and add the extra disk with scheduling enabled
       for the current node.
    4. Create a backing image.
    5. Create and attach a 2-replica volume with the backing image set.
       Then verify:
       1. there is a replica scheduled to the new disk.
       2. there are 2 entries in the backing image disk file status map,
          and both are state `ready`.
    6. Directly mount the volume (without making filesystem) to a directory.
       Then verify the content of the backing image by checking the existence
       of the directory `&lt;Mount point&gt;/guests/`.
    7. Write random data to the mount point then verify the data.
    8. Unmount the host disk. Then verify:
       1. The replica in the host disk will be failed.
       2. The disk state in the backing image will become failed.
       3. The related download pod named
          `&lt;Backing image name&gt;-&lt;First 8 characters of disk UUID&gt;` is removed.
    9. Remount the host disk to another path. Then create another Longhorn disk
       based on the migrated path (disk migration).
    10. Verify the followings.
        1. The disk added in step3 (before the migration) should
           be &#34;unschedulable&#34;.
        2. The disk added in step9 (after the migration) should
           become &#34;schedulable&#34;.
        3. The failed replica will be reused. And the replica DiskID as well as
           the disk path is updated.
        4. The 2-replica volume r/w works fine.
        5. The download state in the backing image will become `downloaded`.
        6. The related download pod will be recreated.
    11. Do cleanup.
    &#34;&#34;&#34;


@pytest.mark.backing_image  # NOQA
def test_exporting_backing_image_from_volume(client, volume_name):  # NOQA
    &#34;&#34;&#34;
    1. Create and attach the 1st volume.
    2. Make a filesystem for the 1st volume.
    3. Export this volume to the 1st backing image
       via the backing image creation HTTP API. And the export type is qcow2.
    4. Create and attach the 2nd volume which uses the 1st backing image.
    5. Make sure the 2nd volume can be directly mount.
    6. Write random data to the mount point then get the checksum.
    7. Unmount and detach the 2nd volume.
    8. Export the 2nd volume as the 2nd backing image.
       Remember to set the export type to qcow2.
    9. Create and attach the 3rd volume which uses the 2nd backing image.
    10. Directly mount the 3rd volume. Then verify the data in the 3rd volume
        is the same as that of the 2nd volume.
    11. Do cleanup.
    &#34;&#34;&#34;

    # Step1, Step2
    hostId = get_self_host_id()
    volume1_name = &#34;vol1&#34;
    volume1 = create_and_check_volume(
        client, volume_name=volume1_name, size=str(1 * Gi))

    volume1 = volume1.attach(hostId=hostId)
    volume1 = wait_for_volume_healthy(client, volume1_name)

    # Step3
    backing_img1_name = &#39;bi-test1&#39;
    backing_img1 = client.create_backing_image(
            name=backing_img1_name,
            sourceType=BACKING_IMAGE_SOURCE_TYPE_FROM_VOLUME,
            parameters={&#34;export-type&#34;: &#34;qcow2&#34;, &#34;volume-name&#34;: volume1_name},
            expectedChecksum=&#34;&#34;)

    # Step4
    volume2_name = &#34;vol2&#34;
    volume2 = create_and_check_volume(
        client, volume_name=volume2_name, size=str(1 * Gi),
        backing_image=backing_img1[&#34;name&#34;])
    volume2 = volume2.attach(hostId=hostId)
    volume2 = wait_for_volume_healthy(client, volume2_name, 300)

    # Step5, 6
    data2 = write_volume_random_data(volume2)

    # Step7
    volume2.detach()
    volume2 = wait_for_volume_detached(client, volume2_name)

    # Step8
    backing_img2 = client.create_backing_image(
            name=&#34;bi-test2&#34;,
            sourceType=BACKING_IMAGE_SOURCE_TYPE_FROM_VOLUME,
            parameters={&#34;export-type&#34;: &#34;qcow2&#34;, &#34;volume-name&#34;: volume2_name},
            expectedChecksum=&#34;&#34;)

    # Step9
    volume3_name = &#34;vol3&#34;
    volume3 = create_and_check_volume(
        client, volume_name=volume3_name, size=str(1 * Gi),
        backing_image=backing_img2[&#34;name&#34;])
    volume3 = volume3.attach(hostId=hostId)
    volume3 = wait_for_volume_healthy(client, volume3_name, 300)

    # Step10
    check_volume_data(volume3, data2)

@pytest.mark.backing_image  # NOQA
@pytest.mark.parametrize(&#34;bi_url&#34;, [BACKING_IMAGE_QCOW2_URL, BACKING_IMAGE_RAW_URL]) # NOQA
def test_backing_image_auto_resync(bi_url, client, volume_name):  # NOQA
    &#34;&#34;&#34;
    1. Create a backing image.
    2. Create and attach a 3-replica volume using the backing image.
    3. Wait for the attachment complete.
    4. Manually remove the backing image on the current node.
    5. Wait for the file state in the disk/on this node become failed.
    6. Wait for the file recovering automatically.
    7. Validate the volume.
    &#34;&#34;&#34;
    # Step 1
    create_backing_image_with_matching_url(
              client, BACKING_IMAGE_NAME, bi_url)

    # Step 2
    volume = create_and_check_volume(
                                     client, volume_name, 3,
                                     str(BACKING_IMAGE_EXT4_SIZE),
                                     BACKING_IMAGE_NAME)

    # Step 3
    lht_host_id = get_self_host_id()
    volume.attach(hostId=lht_host_id)
    volume = wait_for_volume_healthy(client, volume_name)
    assert volume.backingImage == BACKING_IMAGE_NAME
    assert volume.size == str(BACKING_IMAGE_EXT4_SIZE)

    # Step 4
    subprocess.check_output([&#39;rm&#39;, &#39;-rf&#39;, &#39;/var/lib/longhorn/backing-images/&#39;])

    # Step 5
    disk_uuid = get_disk_uuid()
    wait_for_backing_image_in_disk_fail(client, BACKING_IMAGE_NAME, disk_uuid)

    # Step 6
    wait_for_backing_image_status(client, BACKING_IMAGE_NAME,
                                  BACKING_IMAGE_STATE_READY)

    # Step 7
    volume = wait_for_volume_healthy(client, volume_name)
    assert volume.backingImage == BACKING_IMAGE_NAME
    assert volume.size == str(BACKING_IMAGE_EXT4_SIZE)


@pytest.mark.backing_image  # NOQA
def test_backing_image_cleanup(core_api, client):  # NOQA
    &#34;&#34;&#34;
    1. Create multiple backing image.
    2. Create and attach multiple 3-replica volume using those backing image.
    3. Wait for the attachment complete.
    4. Delete the volumes then the backing images.
    5. Verify all backing image manager pods will be terminated when the last
       backing image is gone.
    6. Repeat step1 to step5 for multiple times. Make sure each time the test
       is using the same the backing image namings.
    &#34;&#34;&#34;
    for i in range(3):
        backing_image_cleanup(core_api, client)


def backing_image_cleanup(core_api, client): # NOQA
    # Step 1
    backing_img1_name = &#39;bi-test1&#39;
    create_backing_image_with_matching_url(
            client, backing_img1_name, BACKING_IMAGE_QCOW2_URL)

    backing_img2_name = &#39;bi-test2&#39;
    create_backing_image_with_matching_url(
            client, backing_img2_name, BACKING_IMAGE_RAW_URL)

    # Step 2
    lht_host_id = get_self_host_id()
    volume1 = create_and_check_volume(
        client, volume_name=&#34;vol-1&#34;, size=str(1 * Gi),
        backing_image=backing_img1_name)

    volume2 = create_and_check_volume(
        client, volume_name=&#34;vol-2&#34;, size=str(1 * Gi),
        backing_image=backing_img2_name)

    # Step 3
    volume1.attach(hostId=lht_host_id)
    volume1 = wait_for_volume_healthy(client, volume1.name)
    volume2.attach(hostId=lht_host_id)
    volume2 = wait_for_volume_healthy(client, volume2.name)
    assert volume1.backingImage == backing_img1_name
    assert volume2.backingImage == backing_img2_name

    # Step 4
    cleanup_all_volumes(client)
    cleanup_all_backing_images(client)

    # Step 5
    for i in range(RETRY_EXEC_COUNTS):
        exist = False
        pods = core_api.list_namespaced_pod(LONGHORN_NAMESPACE)
        for pod in pods.items:
            if &#34;backing-image-manager&#34; in pod.metadata.name:
                exist = True
                time.sleep(RETRY_INTERVAL)
                continue
        if exist is False:
            break

    assert exist is False


@pytest.mark.backing_image  # NOQA
@pytest.mark.parametrize(&#34;bi_url&#34;, [BACKING_IMAGE_QCOW2_URL, BACKING_IMAGE_RAW_URL]) # NOQA
def test_backing_image_with_wrong_md5sum(bi_url, client): # NOQA

    backing_image_wrong_checksum = \
            BACKING_IMAGE_QCOW2_CHECKSUM[1:] + BACKING_IMAGE_QCOW2_CHECKSUM[0]

    client.create_backing_image(name=BACKING_IMAGE_NAME,
                                sourceType=BACKING_IMAGE_SOURCE_TYPE_DOWNLOAD,
                                parameters={&#34;url&#34;: bi_url},
                                expectedChecksum=backing_image_wrong_checksum)

    wait_for_backing_image_status(client, BACKING_IMAGE_NAME,
                                  BACKING_IMAGE_STATE_FAILED_AND_CLEANUP)


def test_volume_wait_for_backing_image_condition(client): # NOQA
    &#34;&#34;&#34;
    Test the volume condition &#34;WaitForBackingImage&#34;

    Given
    - Create a BackingImage

    When
    - Creating the Volume with the BackingImage while it is still in progress

    Then
    - The condition &#34;WaitForBackingImage&#34; of the Volume
      would be first True and then change to False when
      the BackingImage is ready and all the replicas are in running state.
    &#34;&#34;&#34;
    # Create a large volume and export as backingimage
    lht_host_id = get_self_host_id()

    volume1_name = &#34;vol1&#34;
    volume1 = create_and_check_volume(
        client, volume1_name, 3,
        str(1 * Gi))
    volume1.attach(hostId=lht_host_id)
    volume1 = wait_for_volume_healthy(client, volume1_name)
    volume_endpoint = get_volume_endpoint(volume1)
    write_volume_dev_random_mb_data(volume_endpoint, 1, 500)
    vol1_cksum = get_device_checksum(volume_endpoint)

    backing_img_name = &#39;bi-test&#39;
    backing_img = client.create_backing_image(
            name=backing_img_name,
            sourceType=BACKING_IMAGE_SOURCE_TYPE_FROM_VOLUME,
            parameters={&#34;export-type&#34;: &#34;qcow2&#34;, &#34;volume-name&#34;: volume1_name},
            expectedChecksum=&#34;&#34;)

    # Create volume with that backing image
    volume2_name = &#34;vol2&#34;
    volume2 = create_and_check_volume(
        client, volume_name=volume2_name, size=str(1 * Gi),
        backing_image=backing_img[&#34;name&#34;])

    volume2.attach(hostId=lht_host_id)

    if check_backing_image_disk_map_status(client,
                                           backing_img_name,
                                           1,
                                           BACKING_IMAGE_STATE_IN_PROGRESS):
        volume2 = client.by_id_volume(volume2_name)
        assert volume2.conditions.WaitForBackingImage.status == &#34;True&#34;

    # Check volume healthy, and backing image ready
    volume2 = wait_for_volume_healthy(client, volume2_name, RETRY_COUNTS_LONG)
    assert volume2.conditions.WaitForBackingImage.status == &#34;False&#34;
    check_backing_image_disk_map_status(client, backing_img_name, 3, &#34;ready&#34;)

    volume_endpoint = get_volume_endpoint(volume2)
    vol2_cksum = get_device_checksum(volume_endpoint)
    assert vol1_cksum == vol2_cksum</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="tests.test_backing_image.backing_image_basic_operation_test"><code class="name flex">
<span>def <span class="ident">backing_image_basic_operation_test</span></span>(<span>client, volume_name, bi_name, bi_url)</span>
</code></dt>
<dd>
<div class="desc"><p>Test Backing Image APIs.</p>
<ol>
<li>Create a backing image.</li>
<li>Create and attach a Volume with the backing image set.</li>
<li>Verify that the all disk states in the backing image are "downloaded".</li>
<li>Try to use the API to manually clean up one disk for the backing image
but get failed.</li>
<li>Try to use the API to directly delete the backing image
but get failed.</li>
<li>Delete the volume.</li>
<li>Use the API to manually clean up one disk for the backing image</li>
<li>Delete the backing image.</li>
</ol></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def backing_image_basic_operation_test(client, volume_name, bi_name, bi_url):  # NOQA
    &#34;&#34;&#34;
    Test Backing Image APIs.

    1. Create a backing image.
    2. Create and attach a Volume with the backing image set.
    3. Verify that the all disk states in the backing image are &#34;downloaded&#34;.
    4. Try to use the API to manually clean up one disk for the backing image
       but get failed.
    5. Try to use the API to directly delete the backing image
       but get failed.
    6. Delete the volume.
    7. Use the API to manually clean up one disk for the backing image
    8. Delete the backing image.
    &#34;&#34;&#34;

    volume = create_and_check_volume(
        client, volume_name, 3,
        str(BACKING_IMAGE_EXT4_SIZE), bi_name)
    lht_host_id = get_self_host_id()
    volume.attach(hostId=lht_host_id)
    volume = wait_for_volume_healthy(client, volume_name)
    assert volume.backingImage == bi_name
    assert volume.size == str(BACKING_IMAGE_EXT4_SIZE)

    random_disk_id = &#34;&#34;
    backing_image = client.by_id_backing_image(bi_name)
    assert backing_image.sourceType == BACKING_IMAGE_SOURCE_TYPE_DOWNLOAD
    assert backing_image.parameters[&#34;url&#34;] == bi_url
    assert backing_image.currentChecksum != &#34;&#34;
    assert not backing_image.deletionTimestamp
    assert len(backing_image.diskFileStatusMap) == 3
    for disk_id, status in iter(backing_image.diskFileStatusMap.items()):
        assert status.state == BACKING_IMAGE_STATE_READY
        random_disk_id = disk_id
    assert random_disk_id != &#39;&#39;

    with pytest.raises(Exception):
        backing_image.backingImageCleanup(disks=[random_disk_id])
    with pytest.raises(Exception):
        client.delete(backing_image)

    client.delete(volume)
    wait_for_volume_delete(client, volume_name)

    backing_image = client.by_id_backing_image(bi_name)
    backing_image.backingImageCleanup(disks=[random_disk_id])
    backing_image = wait_for_backing_image_disk_cleanup(
        client, bi_name, random_disk_id)
    client.delete(backing_image)</code></pre>
</details>
</dd>
<dt id="tests.test_backing_image.backing_image_cleanup"><code class="name flex">
<span>def <span class="ident">backing_image_cleanup</span></span>(<span>core_api, client)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def backing_image_cleanup(core_api, client): # NOQA
    # Step 1
    backing_img1_name = &#39;bi-test1&#39;
    create_backing_image_with_matching_url(
            client, backing_img1_name, BACKING_IMAGE_QCOW2_URL)

    backing_img2_name = &#39;bi-test2&#39;
    create_backing_image_with_matching_url(
            client, backing_img2_name, BACKING_IMAGE_RAW_URL)

    # Step 2
    lht_host_id = get_self_host_id()
    volume1 = create_and_check_volume(
        client, volume_name=&#34;vol-1&#34;, size=str(1 * Gi),
        backing_image=backing_img1_name)

    volume2 = create_and_check_volume(
        client, volume_name=&#34;vol-2&#34;, size=str(1 * Gi),
        backing_image=backing_img2_name)

    # Step 3
    volume1.attach(hostId=lht_host_id)
    volume1 = wait_for_volume_healthy(client, volume1.name)
    volume2.attach(hostId=lht_host_id)
    volume2 = wait_for_volume_healthy(client, volume2.name)
    assert volume1.backingImage == backing_img1_name
    assert volume2.backingImage == backing_img2_name

    # Step 4
    cleanup_all_volumes(client)
    cleanup_all_backing_images(client)

    # Step 5
    for i in range(RETRY_EXEC_COUNTS):
        exist = False
        pods = core_api.list_namespaced_pod(LONGHORN_NAMESPACE)
        for pod in pods.items:
            if &#34;backing-image-manager&#34; in pod.metadata.name:
                exist = True
                time.sleep(RETRY_INTERVAL)
                continue
        if exist is False:
            break

    assert exist is False</code></pre>
</details>
</dd>
<dt id="tests.test_backing_image.backing_image_content_test"><code class="name flex">
<span>def <span class="ident">backing_image_content_test</span></span>(<span>client, volume_name_prefix, bi_name, bi_url)</span>
</code></dt>
<dd>
<div class="desc"><p>Verify the content of the Backing Image is accessible and read-only for
all volumes.</p>
<ol>
<li>Create a backing image. (Done by the caller)</li>
<li>Create a Volume with the backing image set then attach it to host node.</li>
<li>Verify that the all disk states in the backing image are "downloaded".</li>
<li>Verify volume can be directly mounted and there is already data in the
filesystem due to the backing image.</li>
<li>Verify the volume r/w.</li>
<li>Launch one more volume with the same backing image.</li>
<li>Verify the data content of the new volume is the same as the data in
step 4.</li>
<li>Do cleanup. (Done by the caller)</li>
</ol></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def backing_image_content_test(client, volume_name_prefix, bi_name, bi_url):  # NOQA
    &#34;&#34;&#34;
    Verify the content of the Backing Image is accessible and read-only for
    all volumes.

    1. Create a backing image. (Done by the caller)
    2. Create a Volume with the backing image set then attach it to host node.
    3. Verify that the all disk states in the backing image are &#34;downloaded&#34;.
    4. Verify volume can be directly mounted and there is already data in the
       filesystem due to the backing image.
    5. Verify the volume r/w.
    6. Launch one more volume with the same backing image.
    7. Verify the data content of the new volume is the same as the data in
       step 4.
    5. Do cleanup. (Done by the caller)
    &#34;&#34;&#34;
    lht_host_id = get_self_host_id()

    volume_name1 = volume_name_prefix + &#34;-1&#34;
    volume1 = create_and_check_volume(
        client, volume_name1, 3,
        str(BACKING_IMAGE_EXT4_SIZE), bi_name)
    volume1.attach(hostId=lht_host_id)
    volume1 = wait_for_volume_healthy(client, volume_name1)
    assert volume1.backingImage == bi_name
    assert volume1.size == str(BACKING_IMAGE_EXT4_SIZE)

    backing_image = client.by_id_backing_image(bi_name)
    assert backing_image.sourceType == BACKING_IMAGE_SOURCE_TYPE_DOWNLOAD
    assert backing_image.parameters[&#34;url&#34;] == bi_url
    assert backing_image.currentChecksum != &#34;&#34;
    assert not backing_image.deletionTimestamp
    assert len(backing_image.diskFileStatusMap) == 3
    for disk_id, status in iter(backing_image.diskFileStatusMap.items()):
        assert status.state == BACKING_IMAGE_STATE_READY

    # Since there is already a filesystem with data in the backing image,
    # we can directly mount and access the volume without `mkfs`.
    dev1 = get_volume_endpoint(volume1)
    mount_path1 = os.path.join(DIRECTORY_PATH, volume_name1)
    mount_disk(dev1, mount_path1)
    output1 = subprocess.check_output([&#34;ls&#34;, mount_path1])
    # The following random write may crash the filesystem of volume1,
    # need to umount it here
    cleanup_host_disk(volume_name1)

    # Verify r/w for the volume with a backing image
    data = write_volume_random_data(volume1)
    check_volume_data(volume1, data)

    volume_name2 = volume_name_prefix + &#34;-2&#34;
    volume2 = create_and_check_volume(
        client, volume_name2, 3,
        str(BACKING_IMAGE_EXT4_SIZE), bi_name)
    volume2.attach(hostId=lht_host_id)
    volume2 = wait_for_volume_healthy(client, volume_name2)
    assert volume1.backingImage == bi_name
    assert volume1.size == str(BACKING_IMAGE_EXT4_SIZE)
    dev2 = get_volume_endpoint(volume2)
    mount_path2 = os.path.join(DIRECTORY_PATH, volume_name2)
    mount_disk(dev2, mount_path2)
    output2 = subprocess.check_output([&#34;ls&#34;, mount_path2])
    # The output is the content of the backing image, which should keep
    # unchanged
    assert output2 == output1

    cleanup_host_disk(volume_name2)</code></pre>
</details>
</dd>
<dt id="tests.test_backing_image.test_backing_image_auto_resync"><code class="name flex">
<span>def <span class="ident">test_backing_image_auto_resync</span></span>(<span>bi_url, client, volume_name)</span>
</code></dt>
<dd>
<div class="desc"><ol>
<li>Create a backing image.</li>
<li>Create and attach a 3-replica volume using the backing image.</li>
<li>Wait for the attachment complete.</li>
<li>Manually remove the backing image on the current node.</li>
<li>Wait for the file state in the disk/on this node become failed.</li>
<li>Wait for the file recovering automatically.</li>
<li>Validate the volume.</li>
</ol></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@pytest.mark.backing_image  # NOQA
@pytest.mark.parametrize(&#34;bi_url&#34;, [BACKING_IMAGE_QCOW2_URL, BACKING_IMAGE_RAW_URL]) # NOQA
def test_backing_image_auto_resync(bi_url, client, volume_name):  # NOQA
    &#34;&#34;&#34;
    1. Create a backing image.
    2. Create and attach a 3-replica volume using the backing image.
    3. Wait for the attachment complete.
    4. Manually remove the backing image on the current node.
    5. Wait for the file state in the disk/on this node become failed.
    6. Wait for the file recovering automatically.
    7. Validate the volume.
    &#34;&#34;&#34;
    # Step 1
    create_backing_image_with_matching_url(
              client, BACKING_IMAGE_NAME, bi_url)

    # Step 2
    volume = create_and_check_volume(
                                     client, volume_name, 3,
                                     str(BACKING_IMAGE_EXT4_SIZE),
                                     BACKING_IMAGE_NAME)

    # Step 3
    lht_host_id = get_self_host_id()
    volume.attach(hostId=lht_host_id)
    volume = wait_for_volume_healthy(client, volume_name)
    assert volume.backingImage == BACKING_IMAGE_NAME
    assert volume.size == str(BACKING_IMAGE_EXT4_SIZE)

    # Step 4
    subprocess.check_output([&#39;rm&#39;, &#39;-rf&#39;, &#39;/var/lib/longhorn/backing-images/&#39;])

    # Step 5
    disk_uuid = get_disk_uuid()
    wait_for_backing_image_in_disk_fail(client, BACKING_IMAGE_NAME, disk_uuid)

    # Step 6
    wait_for_backing_image_status(client, BACKING_IMAGE_NAME,
                                  BACKING_IMAGE_STATE_READY)

    # Step 7
    volume = wait_for_volume_healthy(client, volume_name)
    assert volume.backingImage == BACKING_IMAGE_NAME
    assert volume.size == str(BACKING_IMAGE_EXT4_SIZE)</code></pre>
</details>
</dd>
<dt id="tests.test_backing_image.test_backing_image_basic_operation"><code class="name flex">
<span>def <span class="ident">test_backing_image_basic_operation</span></span>(<span>client, volume_name)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@pytest.mark.coretest   # NOQA
@pytest.mark.backing_image  # NOQA
def test_backing_image_basic_operation(client, volume_name):  # NOQA
    for bi_url in (BACKING_IMAGE_QCOW2_URL, BACKING_IMAGE_RAW_URL):
        create_backing_image_with_matching_url(
            client, BACKING_IMAGE_NAME, bi_url)
        backing_image_basic_operation_test(
            client, volume_name, BACKING_IMAGE_NAME, bi_url)
        cleanup_all_volumes(client)
        cleanup_all_backing_images(client)</code></pre>
</details>
</dd>
<dt id="tests.test_backing_image.test_backing_image_cleanup"><code class="name flex">
<span>def <span class="ident">test_backing_image_cleanup</span></span>(<span>core_api, client)</span>
</code></dt>
<dd>
<div class="desc"><ol>
<li>Create multiple backing image.</li>
<li>Create and attach multiple 3-replica volume using those backing image.</li>
<li>Wait for the attachment complete.</li>
<li>Delete the volumes then the backing images.</li>
<li>Verify all backing image manager pods will be terminated when the last
backing image is gone.</li>
<li>Repeat step1 to step5 for multiple times. Make sure each time the test
is using the same the backing image namings.</li>
</ol></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@pytest.mark.backing_image  # NOQA
def test_backing_image_cleanup(core_api, client):  # NOQA
    &#34;&#34;&#34;
    1. Create multiple backing image.
    2. Create and attach multiple 3-replica volume using those backing image.
    3. Wait for the attachment complete.
    4. Delete the volumes then the backing images.
    5. Verify all backing image manager pods will be terminated when the last
       backing image is gone.
    6. Repeat step1 to step5 for multiple times. Make sure each time the test
       is using the same the backing image namings.
    &#34;&#34;&#34;
    for i in range(3):
        backing_image_cleanup(core_api, client)</code></pre>
</details>
</dd>
<dt id="tests.test_backing_image.test_backing_image_content"><code class="name flex">
<span>def <span class="ident">test_backing_image_content</span></span>(<span>client, volume_name)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@pytest.mark.coretest   # NOQA
@pytest.mark.backing_image  # NOQA
def test_backing_image_content(client, volume_name):  # NOQA
    for bi_url in (BACKING_IMAGE_QCOW2_URL, BACKING_IMAGE_RAW_URL):
        create_backing_image_with_matching_url(
            client, BACKING_IMAGE_NAME, bi_url)
        backing_image_content_test(
            client, volume_name, BACKING_IMAGE_NAME, bi_url)
        cleanup_all_volumes(client)
        cleanup_all_backing_images(client)</code></pre>
</details>
</dd>
<dt id="tests.test_backing_image.test_backing_image_with_disk_migration"><code class="name flex">
<span>def <span class="ident">test_backing_image_with_disk_migration</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"><ol>
<li>Update settings:</li>
<li>Disable Node Soft Anti-affinity.</li>
<li>Set Replica Replenishment Wait Interval to a relatively long value.</li>
<li>Create a new host disk.</li>
<li>Disable the default disk and add the extra disk with scheduling enabled
for the current node.</li>
<li>Create a backing image.</li>
<li>Create and attach a 2-replica volume with the backing image set.
Then verify:</li>
<li>there is a replica scheduled to the new disk.</li>
<li>there are 2 entries in the backing image disk file status map,
and both are state <code>ready</code>.</li>
<li>Directly mount the volume (without making filesystem) to a directory.
Then verify the content of the backing image by checking the existence
of the directory <code>&lt;Mount point&gt;/guests/</code>.</li>
<li>Write random data to the mount point then verify the data.</li>
<li>Unmount the host disk. Then verify:</li>
<li>The replica in the host disk will be failed.</li>
<li>The disk state in the backing image will become failed.</li>
<li>The related download pod named
<code>&lt;Backing image name&gt;-&lt;First 8 characters of disk UUID&gt;</code> is removed.</li>
<li>Remount the host disk to another path. Then create another Longhorn disk
based on the migrated path (disk migration).</li>
<li>Verify the followings.<ol>
<li>The disk added in step3 (before the migration) should
be "unschedulable".</li>
<li>The disk added in step9 (after the migration) should
become "schedulable".</li>
<li>The failed replica will be reused. And the replica DiskID as well as
the disk path is updated.</li>
<li>The 2-replica volume r/w works fine.</li>
<li>The download state in the backing image will become <code>downloaded</code>.</li>
<li>The related download pod will be recreated.</li>
</ol>
</li>
<li>Do cleanup.</li>
</ol></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@pytest.mark.skip(reason=&#34;TODO&#34;) # NOQA
@pytest.mark.backing_image  # NOQA
def test_backing_image_with_disk_migration():  # NOQA
    &#34;&#34;&#34;
    1. Update settings:
       1. Disable Node Soft Anti-affinity.
       2. Set Replica Replenishment Wait Interval to a relatively long value.
    2. Create a new host disk.
    3. Disable the default disk and add the extra disk with scheduling enabled
       for the current node.
    4. Create a backing image.
    5. Create and attach a 2-replica volume with the backing image set.
       Then verify:
       1. there is a replica scheduled to the new disk.
       2. there are 2 entries in the backing image disk file status map,
          and both are state `ready`.
    6. Directly mount the volume (without making filesystem) to a directory.
       Then verify the content of the backing image by checking the existence
       of the directory `&lt;Mount point&gt;/guests/`.
    7. Write random data to the mount point then verify the data.
    8. Unmount the host disk. Then verify:
       1. The replica in the host disk will be failed.
       2. The disk state in the backing image will become failed.
       3. The related download pod named
          `&lt;Backing image name&gt;-&lt;First 8 characters of disk UUID&gt;` is removed.
    9. Remount the host disk to another path. Then create another Longhorn disk
       based on the migrated path (disk migration).
    10. Verify the followings.
        1. The disk added in step3 (before the migration) should
           be &#34;unschedulable&#34;.
        2. The disk added in step9 (after the migration) should
           become &#34;schedulable&#34;.
        3. The failed replica will be reused. And the replica DiskID as well as
           the disk path is updated.
        4. The 2-replica volume r/w works fine.
        5. The download state in the backing image will become `downloaded`.
        6. The related download pod will be recreated.
    11. Do cleanup.
    &#34;&#34;&#34;</code></pre>
</details>
</dd>
<dt id="tests.test_backing_image.test_backing_image_with_wrong_md5sum"><code class="name flex">
<span>def <span class="ident">test_backing_image_with_wrong_md5sum</span></span>(<span>bi_url, client)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@pytest.mark.backing_image  # NOQA
@pytest.mark.parametrize(&#34;bi_url&#34;, [BACKING_IMAGE_QCOW2_URL, BACKING_IMAGE_RAW_URL]) # NOQA
def test_backing_image_with_wrong_md5sum(bi_url, client): # NOQA

    backing_image_wrong_checksum = \
            BACKING_IMAGE_QCOW2_CHECKSUM[1:] + BACKING_IMAGE_QCOW2_CHECKSUM[0]

    client.create_backing_image(name=BACKING_IMAGE_NAME,
                                sourceType=BACKING_IMAGE_SOURCE_TYPE_DOWNLOAD,
                                parameters={&#34;url&#34;: bi_url},
                                expectedChecksum=backing_image_wrong_checksum)

    wait_for_backing_image_status(client, BACKING_IMAGE_NAME,
                                  BACKING_IMAGE_STATE_FAILED_AND_CLEANUP)</code></pre>
</details>
</dd>
<dt id="tests.test_backing_image.test_backup_labels_with_backing_image"><code class="name flex">
<span>def <span class="ident">test_backup_labels_with_backing_image</span></span>(<span>set_random_backupstore, client, random_labels, volume_name)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@pytest.mark.coretest   # NOQA
@pytest.mark.backing_image  # NOQA
def test_backup_labels_with_backing_image(set_random_backupstore, client, random_labels, volume_name):  # NOQA
    for bi_url in (BACKING_IMAGE_QCOW2_URL, BACKING_IMAGE_RAW_URL):
        create_backing_image_with_matching_url(
            client, BACKING_IMAGE_NAME, bi_url)
        backup_labels_test(client, random_labels, volume_name,
                           str(BACKING_IMAGE_EXT4_SIZE), BACKING_IMAGE_NAME)
        cleanup_all_volumes(client)
        cleanup_all_backing_images(client)
        backupstore_cleanup(client)</code></pre>
</details>
</dd>
<dt id="tests.test_backing_image.test_backup_with_backing_image"><code class="name flex">
<span>def <span class="ident">test_backup_with_backing_image</span></span>(<span>set_random_backupstore, client, volume_name)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@pytest.mark.coretest   # NOQA
@pytest.mark.backing_image  # NOQA
def test_backup_with_backing_image(set_random_backupstore, client, volume_name):  # NOQA
    for bi_url in (BACKING_IMAGE_QCOW2_URL, BACKING_IMAGE_RAW_URL):
        create_backing_image_with_matching_url(
            client, BACKING_IMAGE_NAME, bi_url)
        backup_test(client, volume_name, str(BACKING_IMAGE_EXT4_SIZE),
                    BACKING_IMAGE_NAME)
        cleanup_all_volumes(client)
        cleanup_all_backing_images(client)
        backupstore_cleanup(client)</code></pre>
</details>
</dd>
<dt id="tests.test_backing_image.test_csi_backup_with_backing_image"><code class="name flex">
<span>def <span class="ident">test_csi_backup_with_backing_image</span></span>(<span>set_random_backupstore, client, core_api, csi_pv, pvc, pod_make)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@pytest.mark.coretest  # NOQA
@pytest.mark.backing_image  # NOQA
@pytest.mark.csi  # NOQA
def test_csi_backup_with_backing_image(set_random_backupstore, client, core_api, csi_pv, pvc, pod_make):  # NOQA
    for bi_url in (BACKING_IMAGE_QCOW2_URL, BACKING_IMAGE_RAW_URL):
        create_backing_image_with_matching_url(
            client, BACKING_IMAGE_NAME, bi_url)
        csi_backup_test(client, core_api, csi_pv, pvc, pod_make,
                        BACKING_IMAGE_NAME)
        cleanup_all_volumes(client)
        cleanup_all_backing_images(client)
        backupstore_cleanup(client)</code></pre>
</details>
</dd>
<dt id="tests.test_backing_image.test_csi_io_with_backing_image"><code class="name flex">
<span>def <span class="ident">test_csi_io_with_backing_image</span></span>(<span>client, core_api, csi_pv_backingimage, pvc_backingimage, pod_make)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@pytest.mark.coretest   # NOQA
@pytest.mark.backing_image  # NOQA
@pytest.mark.csi  # NOQA
def test_csi_io_with_backing_image(client, core_api, csi_pv_backingimage, pvc_backingimage, pod_make):  # NOQA
    for bi_url in (BACKING_IMAGE_QCOW2_URL, BACKING_IMAGE_RAW_URL):
        create_backing_image_with_matching_url(
            client, BACKING_IMAGE_NAME, bi_url)
        csi_io_test(client, core_api,
                    csi_pv_backingimage, pvc_backingimage, pod_make)
        cleanup_all_volumes(client)
        cleanup_all_backing_images(client)</code></pre>
</details>
</dd>
<dt id="tests.test_backing_image.test_csi_mount_with_backing_image"><code class="name flex">
<span>def <span class="ident">test_csi_mount_with_backing_image</span></span>(<span>client, core_api, csi_pv_backingimage, pvc_backingimage, pod_make)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@pytest.mark.backing_image  # NOQA
@pytest.mark.csi  # NOQA
def test_csi_mount_with_backing_image(client, core_api, csi_pv_backingimage, pvc_backingimage, pod_make):  # NOQA
    for bi_url in (BACKING_IMAGE_QCOW2_URL, BACKING_IMAGE_RAW_URL):
        create_backing_image_with_matching_url(
            client, BACKING_IMAGE_NAME, bi_url)
        csi_mount_test(client, core_api,
                       csi_pv_backingimage, pvc_backingimage, pod_make,
                       BACKING_IMAGE_EXT4_SIZE, BACKING_IMAGE_NAME)
        cleanup_all_volumes(client)
        cleanup_all_backing_images(client)</code></pre>
</details>
</dd>
<dt id="tests.test_backing_image.test_engine_live_upgrade_rollback_with_backing_image"><code class="name flex">
<span>def <span class="ident">test_engine_live_upgrade_rollback_with_backing_image</span></span>(<span>client, core_api, volume_name)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@pytest.mark.backing_image  # NOQA
def test_engine_live_upgrade_rollback_with_backing_image(client, core_api, volume_name):  # NOQA
    for bi_url in (BACKING_IMAGE_QCOW2_URL, BACKING_IMAGE_RAW_URL):
        create_backing_image_with_matching_url(
            client, BACKING_IMAGE_NAME, bi_url)
        engine_live_upgrade_rollback_test(client, core_api, volume_name,
                                          BACKING_IMAGE_NAME)
        cleanup_all_volumes(client)
        cleanup_all_backing_images(client)</code></pre>
</details>
</dd>
<dt id="tests.test_backing_image.test_engine_live_upgrade_with_backing_image"><code class="name flex">
<span>def <span class="ident">test_engine_live_upgrade_with_backing_image</span></span>(<span>client, core_api, volume_name)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@pytest.mark.coretest   # NOQA
@pytest.mark.backing_image  # NOQA
def test_engine_live_upgrade_with_backing_image(client, core_api, volume_name):  # NOQA
    for bi_url in (BACKING_IMAGE_QCOW2_URL, BACKING_IMAGE_RAW_URL):
        create_backing_image_with_matching_url(
            client, BACKING_IMAGE_NAME, bi_url)
        engine_live_upgrade_test(client, core_api, volume_name,
                                 BACKING_IMAGE_NAME)
        cleanup_all_volumes(client)
        cleanup_all_backing_images(client)</code></pre>
</details>
</dd>
<dt id="tests.test_backing_image.test_engine_offline_upgrade_with_backing_image"><code class="name flex">
<span>def <span class="ident">test_engine_offline_upgrade_with_backing_image</span></span>(<span>client, core_api, volume_name)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@pytest.mark.backing_image  # NOQA
def test_engine_offline_upgrade_with_backing_image(client, core_api, volume_name):  # NOQA
    for bi_url in (BACKING_IMAGE_QCOW2_URL, BACKING_IMAGE_RAW_URL):
        create_backing_image_with_matching_url(
            client, BACKING_IMAGE_NAME, bi_url)
        engine_offline_upgrade_test(client, core_api, volume_name,
                                    BACKING_IMAGE_NAME)
        cleanup_all_volumes(client)
        cleanup_all_backing_images(client)</code></pre>
</details>
</dd>
<dt id="tests.test_backing_image.test_exporting_backing_image_from_volume"><code class="name flex">
<span>def <span class="ident">test_exporting_backing_image_from_volume</span></span>(<span>client, volume_name)</span>
</code></dt>
<dd>
<div class="desc"><ol>
<li>Create and attach the 1st volume.</li>
<li>Make a filesystem for the 1st volume.</li>
<li>Export this volume to the 1st backing image
via the backing image creation HTTP API. And the export type is qcow2.</li>
<li>Create and attach the 2nd volume which uses the 1st backing image.</li>
<li>Make sure the 2nd volume can be directly mount.</li>
<li>Write random data to the mount point then get the checksum.</li>
<li>Unmount and detach the 2nd volume.</li>
<li>Export the 2nd volume as the 2nd backing image.
Remember to set the export type to qcow2.</li>
<li>Create and attach the 3rd volume which uses the 2nd backing image.</li>
<li>Directly mount the 3rd volume. Then verify the data in the 3rd volume
is the same as that of the 2nd volume.</li>
<li>Do cleanup.</li>
</ol></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@pytest.mark.backing_image  # NOQA
def test_exporting_backing_image_from_volume(client, volume_name):  # NOQA
    &#34;&#34;&#34;
    1. Create and attach the 1st volume.
    2. Make a filesystem for the 1st volume.
    3. Export this volume to the 1st backing image
       via the backing image creation HTTP API. And the export type is qcow2.
    4. Create and attach the 2nd volume which uses the 1st backing image.
    5. Make sure the 2nd volume can be directly mount.
    6. Write random data to the mount point then get the checksum.
    7. Unmount and detach the 2nd volume.
    8. Export the 2nd volume as the 2nd backing image.
       Remember to set the export type to qcow2.
    9. Create and attach the 3rd volume which uses the 2nd backing image.
    10. Directly mount the 3rd volume. Then verify the data in the 3rd volume
        is the same as that of the 2nd volume.
    11. Do cleanup.
    &#34;&#34;&#34;

    # Step1, Step2
    hostId = get_self_host_id()
    volume1_name = &#34;vol1&#34;
    volume1 = create_and_check_volume(
        client, volume_name=volume1_name, size=str(1 * Gi))

    volume1 = volume1.attach(hostId=hostId)
    volume1 = wait_for_volume_healthy(client, volume1_name)

    # Step3
    backing_img1_name = &#39;bi-test1&#39;
    backing_img1 = client.create_backing_image(
            name=backing_img1_name,
            sourceType=BACKING_IMAGE_SOURCE_TYPE_FROM_VOLUME,
            parameters={&#34;export-type&#34;: &#34;qcow2&#34;, &#34;volume-name&#34;: volume1_name},
            expectedChecksum=&#34;&#34;)

    # Step4
    volume2_name = &#34;vol2&#34;
    volume2 = create_and_check_volume(
        client, volume_name=volume2_name, size=str(1 * Gi),
        backing_image=backing_img1[&#34;name&#34;])
    volume2 = volume2.attach(hostId=hostId)
    volume2 = wait_for_volume_healthy(client, volume2_name, 300)

    # Step5, 6
    data2 = write_volume_random_data(volume2)

    # Step7
    volume2.detach()
    volume2 = wait_for_volume_detached(client, volume2_name)

    # Step8
    backing_img2 = client.create_backing_image(
            name=&#34;bi-test2&#34;,
            sourceType=BACKING_IMAGE_SOURCE_TYPE_FROM_VOLUME,
            parameters={&#34;export-type&#34;: &#34;qcow2&#34;, &#34;volume-name&#34;: volume2_name},
            expectedChecksum=&#34;&#34;)

    # Step9
    volume3_name = &#34;vol3&#34;
    volume3 = create_and_check_volume(
        client, volume_name=volume3_name, size=str(1 * Gi),
        backing_image=backing_img2[&#34;name&#34;])
    volume3 = volume3.attach(hostId=hostId)
    volume3 = wait_for_volume_healthy(client, volume3_name, 300)

    # Step10
    check_volume_data(volume3, data2)</code></pre>
</details>
</dd>
<dt id="tests.test_backing_image.test_ha_backup_deletion_recovery"><code class="name flex">
<span>def <span class="ident">test_ha_backup_deletion_recovery</span></span>(<span>set_random_backupstore, client, volume_name)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@pytest.mark.backing_image  # NOQA
def test_ha_backup_deletion_recovery(set_random_backupstore, client, volume_name):  # NOQA
    for bi_url in (BACKING_IMAGE_QCOW2_URL, BACKING_IMAGE_RAW_URL):
        create_backing_image_with_matching_url(
            client, BACKING_IMAGE_NAME, bi_url)
        ha_backup_deletion_recovery_test(client, volume_name,
                                         str(BACKING_IMAGE_EXT4_SIZE),
                                         BACKING_IMAGE_NAME)
        cleanup_all_volumes(client)
        cleanup_all_backing_images(client)
        backupstore_cleanup(client)</code></pre>
</details>
</dd>
<dt id="tests.test_backing_image.test_ha_salvage_with_backing_image"><code class="name flex">
<span>def <span class="ident">test_ha_salvage_with_backing_image</span></span>(<span>client, core_api, disable_auto_salvage, volume_name)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@pytest.mark.backing_image  # NOQA
def test_ha_salvage_with_backing_image(client, core_api, disable_auto_salvage, volume_name):  # NOQA
    for bi_url in (BACKING_IMAGE_QCOW2_URL, BACKING_IMAGE_RAW_URL):
        create_backing_image_with_matching_url(
            client, BACKING_IMAGE_NAME, bi_url)
        ha_salvage_test(client, core_api, volume_name, BACKING_IMAGE_NAME)
        cleanup_all_volumes(client)
        cleanup_all_backing_images(client)</code></pre>
</details>
</dd>
<dt id="tests.test_backing_image.test_ha_simple_recovery_with_backing_image"><code class="name flex">
<span>def <span class="ident">test_ha_simple_recovery_with_backing_image</span></span>(<span>client, volume_name)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@pytest.mark.coretest   # NOQA
@pytest.mark.backing_image  # NOQA
def test_ha_simple_recovery_with_backing_image(client, volume_name):  # NOQA
    for bi_url in (BACKING_IMAGE_QCOW2_URL, BACKING_IMAGE_RAW_URL):
        create_backing_image_with_matching_url(
            client, BACKING_IMAGE_NAME, bi_url)
        ha_simple_recovery_test(client, volume_name,
                                str(BACKING_IMAGE_EXT4_SIZE),
                                BACKING_IMAGE_NAME)
        cleanup_all_volumes(client)
        cleanup_all_backing_images(client)</code></pre>
</details>
</dd>
<dt id="tests.test_backing_image.test_recurring_job_labels_with_backing_image"><code class="name flex">
<span>def <span class="ident">test_recurring_job_labels_with_backing_image</span></span>(<span>set_random_backupstore, client, random_labels, volume_name)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@pytest.mark.backing_image  # NOQA
@pytest.mark.recurring_job  # NOQA
def test_recurring_job_labels_with_backing_image(set_random_backupstore, client, random_labels, volume_name):  # NOQA
    for bi_url in (BACKING_IMAGE_QCOW2_URL, BACKING_IMAGE_RAW_URL):
        create_backing_image_with_matching_url(
            client, BACKING_IMAGE_NAME, bi_url)
        recurring_job_labels_test(client, random_labels, volume_name,
                                  str(BACKING_IMAGE_EXT4_SIZE),
                                  BACKING_IMAGE_NAME)
        cleanup_all_recurring_jobs(client)
        cleanup_all_volumes(client)
        cleanup_all_backing_images(client)
        backupstore_cleanup(client)</code></pre>
</details>
</dd>
<dt id="tests.test_backing_image.test_snapshot_prune_and_coalesce_simultaneously_with_backing_image"><code class="name flex">
<span>def <span class="ident">test_snapshot_prune_and_coalesce_simultaneously_with_backing_image</span></span>(<span>client, volume_name)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@pytest.mark.coretest   # NOQA
@pytest.mark.backing_image  # NOQA
def test_snapshot_prune_and_coalesce_simultaneously_with_backing_image(client, volume_name):  # NOQA
    for bi_url in (BACKING_IMAGE_QCOW2_URL, BACKING_IMAGE_RAW_URL):
        create_backing_image_with_matching_url(
            client, BACKING_IMAGE_NAME, bi_url)
        snapshot_prune_and_coalesce_simultaneously(
            client, volume_name, BACKING_IMAGE_NAME)
        cleanup_all_volumes(client)
        cleanup_all_backing_images(client)</code></pre>
</details>
</dd>
<dt id="tests.test_backing_image.test_snapshot_prune_with_backing_image"><code class="name flex">
<span>def <span class="ident">test_snapshot_prune_with_backing_image</span></span>(<span>client, volume_name)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@pytest.mark.coretest   # NOQA
@pytest.mark.backing_image  # NOQA
def test_snapshot_prune_with_backing_image(client, volume_name):  # NOQA
    for bi_url in (BACKING_IMAGE_QCOW2_URL, BACKING_IMAGE_RAW_URL):
        create_backing_image_with_matching_url(
            client, BACKING_IMAGE_NAME, bi_url)
        snapshot_prune_test(client, volume_name, BACKING_IMAGE_NAME)
        cleanup_all_volumes(client)
        cleanup_all_backing_images(client)</code></pre>
</details>
</dd>
<dt id="tests.test_backing_image.test_snapshot_with_backing_image"><code class="name flex">
<span>def <span class="ident">test_snapshot_with_backing_image</span></span>(<span>client, volume_name)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@pytest.mark.coretest   # NOQA
@pytest.mark.backing_image  # NOQA
def test_snapshot_with_backing_image(client, volume_name):  # NOQA
    for bi_url in (BACKING_IMAGE_QCOW2_URL, BACKING_IMAGE_RAW_URL):
        create_backing_image_with_matching_url(
            client, BACKING_IMAGE_NAME, bi_url)
        snapshot_test(client, volume_name, BACKING_IMAGE_NAME)
        cleanup_all_volumes(client)
        cleanup_all_backing_images(client)</code></pre>
</details>
</dd>
<dt id="tests.test_backing_image.test_volume_basic_with_backing_image"><code class="name flex">
<span>def <span class="ident">test_volume_basic_with_backing_image</span></span>(<span>client, volume_name)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@pytest.mark.coretest   # NOQA
@pytest.mark.backing_image  # NOQA
def test_volume_basic_with_backing_image(client, volume_name):  # NOQA
    for bi_url in (BACKING_IMAGE_QCOW2_URL, BACKING_IMAGE_RAW_URL):
        create_backing_image_with_matching_url(
            client, BACKING_IMAGE_NAME, bi_url)
        volume_basic_test(client, volume_name, BACKING_IMAGE_NAME)
        cleanup_all_volumes(client)
        cleanup_all_backing_images(client)</code></pre>
</details>
</dd>
<dt id="tests.test_backing_image.test_volume_iscsi_basic_with_backing_image"><code class="name flex">
<span>def <span class="ident">test_volume_iscsi_basic_with_backing_image</span></span>(<span>client, volume_name)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@pytest.mark.coretest   # NOQA
@pytest.mark.backing_image  # NOQA
def test_volume_iscsi_basic_with_backing_image(client, volume_name):  # NOQA
    for bi_url in (BACKING_IMAGE_QCOW2_URL, BACKING_IMAGE_RAW_URL):
        create_backing_image_with_matching_url(
            client, BACKING_IMAGE_NAME, bi_url)
        volume_iscsi_basic_test(client, volume_name, BACKING_IMAGE_NAME)
        cleanup_all_volumes(client)
        cleanup_all_backing_images(client)</code></pre>
</details>
</dd>
<dt id="tests.test_backing_image.test_volume_wait_for_backing_image_condition"><code class="name flex">
<span>def <span class="ident">test_volume_wait_for_backing_image_condition</span></span>(<span>client)</span>
</code></dt>
<dd>
<div class="desc"><p>Test the volume condition "WaitForBackingImage"</p>
<p>Given
- Create a BackingImage</p>
<p>When
- Creating the Volume with the BackingImage while it is still in progress</p>
<p>Then
- The condition "WaitForBackingImage" of the Volume
would be first True and then change to False when
the BackingImage is ready and all the replicas are in running state.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def test_volume_wait_for_backing_image_condition(client): # NOQA
    &#34;&#34;&#34;
    Test the volume condition &#34;WaitForBackingImage&#34;

    Given
    - Create a BackingImage

    When
    - Creating the Volume with the BackingImage while it is still in progress

    Then
    - The condition &#34;WaitForBackingImage&#34; of the Volume
      would be first True and then change to False when
      the BackingImage is ready and all the replicas are in running state.
    &#34;&#34;&#34;
    # Create a large volume and export as backingimage
    lht_host_id = get_self_host_id()

    volume1_name = &#34;vol1&#34;
    volume1 = create_and_check_volume(
        client, volume1_name, 3,
        str(1 * Gi))
    volume1.attach(hostId=lht_host_id)
    volume1 = wait_for_volume_healthy(client, volume1_name)
    volume_endpoint = get_volume_endpoint(volume1)
    write_volume_dev_random_mb_data(volume_endpoint, 1, 500)
    vol1_cksum = get_device_checksum(volume_endpoint)

    backing_img_name = &#39;bi-test&#39;
    backing_img = client.create_backing_image(
            name=backing_img_name,
            sourceType=BACKING_IMAGE_SOURCE_TYPE_FROM_VOLUME,
            parameters={&#34;export-type&#34;: &#34;qcow2&#34;, &#34;volume-name&#34;: volume1_name},
            expectedChecksum=&#34;&#34;)

    # Create volume with that backing image
    volume2_name = &#34;vol2&#34;
    volume2 = create_and_check_volume(
        client, volume_name=volume2_name, size=str(1 * Gi),
        backing_image=backing_img[&#34;name&#34;])

    volume2.attach(hostId=lht_host_id)

    if check_backing_image_disk_map_status(client,
                                           backing_img_name,
                                           1,
                                           BACKING_IMAGE_STATE_IN_PROGRESS):
        volume2 = client.by_id_volume(volume2_name)
        assert volume2.conditions.WaitForBackingImage.status == &#34;True&#34;

    # Check volume healthy, and backing image ready
    volume2 = wait_for_volume_healthy(client, volume2_name, RETRY_COUNTS_LONG)
    assert volume2.conditions.WaitForBackingImage.status == &#34;False&#34;
    check_backing_image_disk_map_status(client, backing_img_name, 3, &#34;ready&#34;)

    volume_endpoint = get_volume_endpoint(volume2)
    vol2_cksum = get_device_checksum(volume_endpoint)
    assert vol1_cksum == vol2_cksum</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="tests" href="index.html">tests</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="tests.test_backing_image.backing_image_basic_operation_test" href="#tests.test_backing_image.backing_image_basic_operation_test">backing_image_basic_operation_test</a></code></li>
<li><code><a title="tests.test_backing_image.backing_image_cleanup" href="#tests.test_backing_image.backing_image_cleanup">backing_image_cleanup</a></code></li>
<li><code><a title="tests.test_backing_image.backing_image_content_test" href="#tests.test_backing_image.backing_image_content_test">backing_image_content_test</a></code></li>
<li><code><a title="tests.test_backing_image.test_backing_image_auto_resync" href="#tests.test_backing_image.test_backing_image_auto_resync">test_backing_image_auto_resync</a></code></li>
<li><code><a title="tests.test_backing_image.test_backing_image_basic_operation" href="#tests.test_backing_image.test_backing_image_basic_operation">test_backing_image_basic_operation</a></code></li>
<li><code><a title="tests.test_backing_image.test_backing_image_cleanup" href="#tests.test_backing_image.test_backing_image_cleanup">test_backing_image_cleanup</a></code></li>
<li><code><a title="tests.test_backing_image.test_backing_image_content" href="#tests.test_backing_image.test_backing_image_content">test_backing_image_content</a></code></li>
<li><code><a title="tests.test_backing_image.test_backing_image_with_disk_migration" href="#tests.test_backing_image.test_backing_image_with_disk_migration">test_backing_image_with_disk_migration</a></code></li>
<li><code><a title="tests.test_backing_image.test_backing_image_with_wrong_md5sum" href="#tests.test_backing_image.test_backing_image_with_wrong_md5sum">test_backing_image_with_wrong_md5sum</a></code></li>
<li><code><a title="tests.test_backing_image.test_backup_labels_with_backing_image" href="#tests.test_backing_image.test_backup_labels_with_backing_image">test_backup_labels_with_backing_image</a></code></li>
<li><code><a title="tests.test_backing_image.test_backup_with_backing_image" href="#tests.test_backing_image.test_backup_with_backing_image">test_backup_with_backing_image</a></code></li>
<li><code><a title="tests.test_backing_image.test_csi_backup_with_backing_image" href="#tests.test_backing_image.test_csi_backup_with_backing_image">test_csi_backup_with_backing_image</a></code></li>
<li><code><a title="tests.test_backing_image.test_csi_io_with_backing_image" href="#tests.test_backing_image.test_csi_io_with_backing_image">test_csi_io_with_backing_image</a></code></li>
<li><code><a title="tests.test_backing_image.test_csi_mount_with_backing_image" href="#tests.test_backing_image.test_csi_mount_with_backing_image">test_csi_mount_with_backing_image</a></code></li>
<li><code><a title="tests.test_backing_image.test_engine_live_upgrade_rollback_with_backing_image" href="#tests.test_backing_image.test_engine_live_upgrade_rollback_with_backing_image">test_engine_live_upgrade_rollback_with_backing_image</a></code></li>
<li><code><a title="tests.test_backing_image.test_engine_live_upgrade_with_backing_image" href="#tests.test_backing_image.test_engine_live_upgrade_with_backing_image">test_engine_live_upgrade_with_backing_image</a></code></li>
<li><code><a title="tests.test_backing_image.test_engine_offline_upgrade_with_backing_image" href="#tests.test_backing_image.test_engine_offline_upgrade_with_backing_image">test_engine_offline_upgrade_with_backing_image</a></code></li>
<li><code><a title="tests.test_backing_image.test_exporting_backing_image_from_volume" href="#tests.test_backing_image.test_exporting_backing_image_from_volume">test_exporting_backing_image_from_volume</a></code></li>
<li><code><a title="tests.test_backing_image.test_ha_backup_deletion_recovery" href="#tests.test_backing_image.test_ha_backup_deletion_recovery">test_ha_backup_deletion_recovery</a></code></li>
<li><code><a title="tests.test_backing_image.test_ha_salvage_with_backing_image" href="#tests.test_backing_image.test_ha_salvage_with_backing_image">test_ha_salvage_with_backing_image</a></code></li>
<li><code><a title="tests.test_backing_image.test_ha_simple_recovery_with_backing_image" href="#tests.test_backing_image.test_ha_simple_recovery_with_backing_image">test_ha_simple_recovery_with_backing_image</a></code></li>
<li><code><a title="tests.test_backing_image.test_recurring_job_labels_with_backing_image" href="#tests.test_backing_image.test_recurring_job_labels_with_backing_image">test_recurring_job_labels_with_backing_image</a></code></li>
<li><code><a title="tests.test_backing_image.test_snapshot_prune_and_coalesce_simultaneously_with_backing_image" href="#tests.test_backing_image.test_snapshot_prune_and_coalesce_simultaneously_with_backing_image">test_snapshot_prune_and_coalesce_simultaneously_with_backing_image</a></code></li>
<li><code><a title="tests.test_backing_image.test_snapshot_prune_with_backing_image" href="#tests.test_backing_image.test_snapshot_prune_with_backing_image">test_snapshot_prune_with_backing_image</a></code></li>
<li><code><a title="tests.test_backing_image.test_snapshot_with_backing_image" href="#tests.test_backing_image.test_snapshot_with_backing_image">test_snapshot_with_backing_image</a></code></li>
<li><code><a title="tests.test_backing_image.test_volume_basic_with_backing_image" href="#tests.test_backing_image.test_volume_basic_with_backing_image">test_volume_basic_with_backing_image</a></code></li>
<li><code><a title="tests.test_backing_image.test_volume_iscsi_basic_with_backing_image" href="#tests.test_backing_image.test_volume_iscsi_basic_with_backing_image">test_volume_iscsi_basic_with_backing_image</a></code></li>
<li><code><a title="tests.test_backing_image.test_volume_wait_for_backing_image_condition" href="#tests.test_backing_image.test_volume_wait_for_backing_image_condition">test_volume_wait_for_backing_image_condition</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>